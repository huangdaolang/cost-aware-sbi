{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dbb6902",
   "metadata": {},
   "source": [
    "# Temporal SIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed06cb3d",
   "metadata": {},
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from sbi import utils as utils\n",
    "from sbi import analysis as analysis\n",
    "from cost_aware_snpe_c import CostAwareSNPE_C\n",
    "from sbi.inference.snpe.snpe_c import SNPE_C\n",
    "from sbi.utils.torchutils import *\n",
    "from sbi.utils import process_prior\n",
    "from sbi.utils.user_input_checks import *\n",
    "from simulators import temporal_sir\n",
    "\n",
    "from hydra import compose, initialize\n",
    "import hydra\n",
    "\n",
    "import gpytorch\n",
    "from gpytorch.models import ExactGP\n",
    "from gpytorch.kernels import ScaleKernel, RBFKernel\n",
    "from gpytorch.means import ConstantMean\n",
    "from gpytorch.distributions import MultivariateNormal\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "hydra.core.global_hydra.GlobalHydra.instance().clear()\n",
    "initialize(config_path=\"configs\", version_base=None)\n",
    "cfg = compose(config_name=\"train\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77dc6ef3",
   "metadata": {},
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "matplotlib.rcParams.update({\n",
    "    'font.family' : 'times',\n",
    "    'font.size' : 14.0,\n",
    "    'lines.linewidth' : 2,\n",
    "    'lines.antialiased' : True,\n",
    "    'axes.facecolor': 'fdfdfd',\n",
    "    'axes.edgecolor': '777777',\n",
    "    'axes.linewidth' : 1,\n",
    "    'axes.titlesize' : 'medium',\n",
    "    'axes.labelsize' : 'medium',\n",
    "    'axes.axisbelow' : True,\n",
    "    'xtick.major.size'     : 0,      # major tick size in points\n",
    "    'xtick.minor.size'     : 0,      # minor tick size in points\n",
    "    'xtick.major.pad'      : 6,      # distance to major tick label in points\n",
    "    'xtick.minor.pad'      : 6,      # distance to the minor tick label in points\n",
    "    'xtick.color'          : '333333', # color of the tick labels\n",
    "    'xtick.labelsize'      : 'medium', # fontsize of the tick labels\n",
    "    'xtick.direction'      : 'in',     # direction: in or out\n",
    "    'ytick.major.size'     : 0,      # major tick size in points\n",
    "    'ytick.minor.size'     : 0,      # minor tick size in points\n",
    "    'ytick.major.pad'      : 6,      # distance to major tick label in points\n",
    "    'ytick.minor.pad'      : 6,      # distance to the minor tick label in points\n",
    "    'ytick.color'          : '333333', # color of the tick labels\n",
    "    'ytick.labelsize'      : 'medium', # fontsize of the tick labels\n",
    "    'ytick.direction'      : 'in',     # direction: in or out\n",
    "    'axes.grid' : False,\n",
    "    'grid.alpha' : 0.3,\n",
    "    'grid.linewidth' : 1,\n",
    "    'legend.fancybox' : True,\n",
    "    'legend.fontsize' : 'Small',\n",
    "    'figure.figsize' : (2.5, 2.5),\n",
    "    'figure.facecolor' : '1.0',\n",
    "    'figure.edgecolor' : '0.5',\n",
    "    'hatch.linewidth' : 0.1,\n",
    "    'text.usetex' : False\n",
    "    })\n",
    "\n",
    "color_map = {'green': '#009E60', 'orange': '#C04000',\n",
    "              'blue': '#00416A', 'black':'#3A3B3C',\n",
    "              'purple': '#843B62', 'red': '#C41E3A'}\n",
    "\n",
    "\n",
    "plt.rcParams['text.latex.preamble'] = r'\\usepackage{serif}'"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b9f2164",
   "metadata": {},
   "source": [
    "def MMD_unweighted(x, y, lengthscale):\n",
    "    \"\"\" Approximates the squared MMD between samples x_i ~ P and y_i ~ Q\n",
    "    \"\"\"\n",
    "\n",
    "    m = x.shape[0]\n",
    "    n = y.shape[0]\n",
    "\n",
    "    z = torch.cat((x, y), dim=0)\n",
    "\n",
    "    K = kernel_matrix(z, z, lengthscale)\n",
    "\n",
    "    kxx = K[0:m, 0:m]\n",
    "    kyy = K[m:(m + n), m:(m + n)]\n",
    "    kxy = K[0:m, m:(m + n)]\n",
    "\n",
    "    return (1 / m ** 2) * torch.sum(kxx) - (2 / (m * n)) * torch.sum(kxy) + (1 / n ** 2) * torch.sum(kyy)\n",
    "\n",
    "\n",
    "def median_heuristic(y):\n",
    "    a = torch.cdist(y, y)**2\n",
    "    return torch.sqrt(torch.median(a / 2))\n",
    "\n",
    "\n",
    "def kernel_matrix(x, y, l):\n",
    "    d = torch.cdist(x, y)**2\n",
    "\n",
    "    kernel = torch.exp(-(1 / (2 * l ** 2)) * d)\n",
    "\n",
    "    return kernel"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f456b12e",
   "metadata": {},
   "source": [
    "def calc_acc_prob(gp, likelihood, theta, prior_start, k):\n",
    "\n",
    "    with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "        cost = likelihood(model(theta)).mean\n",
    "\n",
    "        lower_cost = likelihood(model(prior_start)).mean\n",
    "    return (lower_cost ** k) / (cost**k)\n",
    "\n",
    "class GP(ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(GP, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = ConstantMean()\n",
    "        self.covar_module = ScaleKernel(RBFKernel())\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return MultivariateNormal(mean_x, covar_x)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a008455c",
   "metadata": {},
   "source": [
    "temp_sir = temporal_sir.TemporalSIR()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "168526c5",
   "metadata": {},
   "source": [
    "## data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d9af0cc6",
   "metadata": {},
   "source": [
    "# DON'T NEED TO RUN\n",
    "N = 50000\n",
    "\n",
    "temp_sir_theta_npe_large = temp_sir.sample_theta([N]).reshape(-1, temp_sir.theta_dim)\n",
    "temp_sir_x_npe_large = torch.empty([N, temp_sir.x_dim])\n",
    "for i in range(N):\n",
    "    temp_sir_x_npe_large[i, :] = temp_sir(temp_sir_theta_npe_large[i])\n",
    "\n",
    "torch.save(temp_sir_x_npe_large, \"data/temp_sir_x_npe_large.pt\")\n",
    "torch.save(temp_sir_theta_npe_large, \"data/temp_sir_theta_npe_large.pt\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "f892d8e3",
   "metadata": {},
   "source": [
    "# DON'T NEED TO RUN\n",
    "temp_sir_obs_theta = torch.tensor([0.5, 0.5])\n",
    "temp_sir_obs_x = temp_sir(temp_sir_obs_theta)\n",
    "temp_sir_obs_x"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "86633e3b",
   "metadata": {},
   "source": [
    "# DON'T NEED TO RUN\n",
    "torch.save(temp_sir_obs_x, \"data/temp_sir_obs_x.pt\")\n",
    "torch.save(temp_sir_obs_theta, \"data/temp_sir_obs_theta.pt\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "3025423c",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2ec4400",
   "metadata": {},
   "source": [
    "temp_sir_x_npe_large = torch.load(\"data/temp_sir_x_npe_large.pt\")\n",
    "temp_sir_theta_npe_large = torch.load(\"data/temp_sir_theta_npe_large.pt\")\n",
    "\n",
    "temp_sir_obs_x = torch.load(\"data/temp_sir_obs_x.pt\")\n",
    "temp_sir_obs_theta = torch.load(\"data/temp_sir_obs_theta.pt\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "342c7fce",
   "metadata": {},
   "source": [
    "## Fit GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a2275d8a",
   "metadata": {},
   "source": [
    "# for gp\n",
    "n_train_pair = 200\n",
    "X = temp_sir_theta_npe_large[:n_train_pair]\n",
    "n_rep = 20\n",
    "\n",
    "times_train = torch.zeros(n_train_pair)\n",
    "\n",
    "for i in range(n_train_pair):\n",
    "    st = time.time()\n",
    "    for _ in range(n_rep):\n",
    "        result = temp_sir(temp_sir_theta_npe_large[i])\n",
    "    et = time.time()\n",
    "    times_train[i] = et - st"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1c0d4fb8",
   "metadata": {},
   "source": [
    "# save GP training samples\n",
    "torch.save(X, \"data/temp_sir_gp_x.pt\")\n",
    "torch.save(times_train, \"data/temp_sir_gp_y.pt\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3f311377",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = GP(X, times_train, likelihood)\n",
    "model.float()\n",
    "model.train()\n",
    "likelihood.train()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "mll = ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "training_iterations = 100\n",
    "for i in range(training_iterations):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(X.float())\n",
    "    loss = -mll(output, times_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f'Iter {i + 1}/{training_iterations} - Loss: {loss.item()}')\n",
    "\n",
    "\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'likelihood_state_dict': likelihood.state_dict()\n",
    "}, 'data/temp_sir_gp.pth')\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "52d58f85",
   "metadata": {},
   "source": [
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "N = 100\n",
    "\n",
    "beta = torch.linspace(0.1, 1, N)\n",
    "beta_fixed = 1\n",
    "\n",
    "\n",
    "gamma_fixed = 0.1\n",
    "gamma = torch.linspace(0.1, 1, N)\n",
    "\n",
    "beta_fixed_combined = beta_fixed * torch.ones_like(gamma)\n",
    "combination_beta_fixed_gamma = torch.stack((beta_fixed_combined, gamma), dim=1)\n",
    "\n",
    "gamma_fixed_combined = gamma_fixed * torch.ones_like(beta)\n",
    "combination_beta_gamma_fixed = torch.stack((beta, gamma_fixed_combined), dim=1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e1e191b6",
   "metadata": {},
   "source": [
    "times_vs_beta = torch.zeros(N)\n",
    "for i in range(N):\n",
    "    st = time.time()\n",
    "    for _ in range(n_rep):\n",
    "        result = temp_sir(combination_beta_gamma_fixed[i])\n",
    "    et = time.time()\n",
    "    times_vs_beta[i] = (et - st)\n",
    "\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    observed_pred = likelihood(model(combination_beta_gamma_fixed)).mean\n",
    "\n",
    "plt.figure(figsize=[5,5])\n",
    "plt.scatter(beta, observed_pred, label=\"GP\")\n",
    "plt.scatter(beta, times_vs_beta, label=\"True\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "09e0ae2f",
   "metadata": {},
   "source": [
    "times_vs_gamma = torch.zeros(N)\n",
    "for i in range(N):\n",
    "    st = time.time()\n",
    "    for _ in range(n_rep):\n",
    "        result = temp_sir(combination_beta_fixed_gamma[i])\n",
    "    et = time.time()\n",
    "    times_vs_gamma[i] = (et - st)\n",
    "\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    observed_pred = likelihood(model(combination_beta_fixed_gamma)).mean\n",
    "\n",
    "plt.figure(figsize=[5,5])\n",
    "plt.scatter(gamma, observed_pred, label=\"GP\")\n",
    "plt.scatter(gamma, times_vs_gamma, label=\"True\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fa5d020",
   "metadata": {},
   "source": [
    "# Load trained GP\n",
    "state_dicts = torch.load('data/temp_sir_gp.pth')\n",
    "\n",
    "X = torch.load(\"data/temp_sir_gp_x.pt\")\n",
    "times_train = torch.load(\"data/temp_sir_gp_y.pt\")\n",
    "\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = GP(X, times_train, likelihood)\n",
    "\n",
    "model.load_state_dict(state_dicts['model_state_dict'])\n",
    "likelihood.load_state_dict(state_dicts['likelihood_state_dict'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "370c8db5",
   "metadata": {},
   "source": [
    "model.eval()\n",
    "likelihood.eval()\n",
    "\n",
    "prior_start = torch.tensor([0.1, 1.0]).reshape(-1, 2)\n",
    "k = 1\n",
    "\n",
    "num_sim = 5000\n",
    "theta_tilde = torch.zeros([num_sim, 2])\n",
    "count = 0\n",
    "while count < num_sim:\n",
    "    theta = temp_sir.sample_theta([1]).reshape(-1, 2)\n",
    "    if calc_acc_prob(model, likelihood, theta, prior_start, k) > torch.rand(1):\n",
    "        theta_tilde[count] = theta.reshape(-1)\n",
    "        count += 1"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "19a50ce6",
   "metadata": {},
   "source": [
    "w = likelihood(model(theta_tilde)).mean.detach() ** k"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "24318faa",
   "metadata": {},
   "source": [
    "theta_prior = temp_sir.sample_theta([5000]).reshape(-1, 2)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "affb5ee4",
   "metadata": {},
   "source": [
    "plt.hist(theta_prior.detach().numpy()[:, 0], bins=10)\n",
    "plt.hist(theta_tilde.detach().numpy()[:, 0], bins=10)\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5965afa7",
   "metadata": {},
   "source": [
    "likelihood(model(torch.tensor([0.1, 1.0]).reshape(1, 2))).mean"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ee18629a",
   "metadata": {},
   "source": [
    "likelihood(model(torch.tensor([0.5, 0.1]).reshape(1, 2))).mean"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "707037b9",
   "metadata": {},
   "source": [
    "## CEG ESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4bf59ea9",
   "metadata": {},
   "source": [
    "num_sim = 10000\n",
    "num_repeats = 2\n",
    "k = np.array([0, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]) # Exponent of the penaly function g(z) = z^k\n",
    "\n",
    "ess_cost_aware = np.zeros([k.size, num_repeats])\n",
    "ceg = np.zeros([k.size, num_repeats])\n",
    "\n",
    "for ind in range(k.size):\n",
    "    for j in range(num_repeats):\n",
    "        \n",
    "        if ind == 0:\n",
    "            theta = temp_sir.sample_theta([num_sim])\n",
    "            ess_cost_aware[ind, j] = 1\n",
    "            ceg[ind, j] = 1\n",
    "        else:\n",
    "            # Sampling from cost-modified prior\n",
    "            theta_tilde = torch.zeros([num_sim, 2])\n",
    "            count = 0\n",
    "            while count < num_sim:\n",
    "                param_value = temp_sir.sample_theta([1]).reshape(-1, 2)\n",
    "                if calc_acc_prob(model, likelihood, param_value, prior_start, k[ind]) > torch.rand(1):\n",
    "                    theta_tilde[count] = param_value.reshape(-1)\n",
    "                    count += 1\n",
    "\n",
    "            w_u = likelihood(model(theta_tilde)).mean.detach() ** k[ind]   #self-normalised importance weights\n",
    "            \n",
    "            # Compute CEG\n",
    "            ceg[ind, j] = torch.mean(likelihood(model(theta)).mean.detach()) / torch.mean(likelihood(model(theta_tilde)).mean.detach())\n",
    "            # Compute ESS\n",
    "            ess_cost_aware[ind, j] = ((w_u.sum())**2 / torch.square(w_u).sum()) / num_sim\n",
    "    print(ind)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "adcbb032",
   "metadata": {},
   "source": [
    "ess_cost_aware * ceg"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "09f4a0b8",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "80fa4df8",
   "metadata": {},
   "source": [
    "# DON'T NEED TO RUN\n",
    "temp_sir_inference_npe_large = SNPE_C()\n",
    "temp_sir_nn_npe_large = temp_sir_inference_npe_large.append_simulations(\n",
    "    temp_sir_theta_npe_large, temp_sir_x_npe_large).train()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "6df0255b",
   "metadata": {},
   "source": [
    "# DON'T NEED TO RUN\n",
    "prior, *_ = process_prior(temp_sir.prior)\n",
    "\n",
    "temp_sir_post_npe_large = temp_sir_inference_npe_large.build_posterior(temp_sir_nn_npe_large, prior=prior)\n",
    "temp_sir_samples_npe_large = temp_sir_post_npe_large.sample((1000,), x=temp_sir_obs_x)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "55f0d0f0",
   "metadata": {},
   "source": [
    "# DON'T NEED TO RUN\n",
    "torch.save(temp_sir_samples_npe_large, \"data/temp_sir_post_reference.pt\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "e200220a",
   "metadata": {},
   "source": [
    "temp_sir_post_reference = torch.load(\"data/temp_sir_post_reference.pt\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "b7a7881b",
   "metadata": {},
   "source": [
    "k = 0.5\n",
    "n_run = 50\n",
    "mmd_npe = torch.zeros([n_run])\n",
    "posterior_samples_npe = torch.zeros([n_run, 1000, 2])\n",
    "cost_npe = torch.zeros([n_run])\n",
    "mmd_canpe = torch.zeros([n_run])\n",
    "posterior_samples_canpe = torch.zeros([n_run, 1000, 2])\n",
    "cost_canpe = torch.zeros([n_run])\n",
    "\n",
    "cost_saved = torch.zeros([n_run])\n",
    "\n",
    "for i in range(n_run):\n",
    "    checkpoint_path = f\"sims/temp_sir/{k}/{i+1}/ckpt.tar\"\n",
    "    checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "\n",
    "    posterior_npe = checkpoint[\"posterior_npe\"]\n",
    "    posterior_canpe = checkpoint[\"posterior_canpe\"]\n",
    "    \n",
    "\n",
    "#     posterior_samples_npe[i] = checkpoint[\"posterior_samples_npe\"]\n",
    "#     posterior_samples_canpe[i] = checkpoint[\"posterior_samples_canpe\"]\n",
    "    \n",
    "    posterior_samples_npe[i] = posterior_npe.sample((1000,), x=temp_sir_obs_x, show_progress_bars=False)\n",
    "    posterior_samples_canpe[i] = posterior_canpe.sample((1000,), x=temp_sir_obs_x, show_progress_bars=False)\n",
    "    \n",
    "    mmd_npe[i] = MMD_unweighted(posterior_samples_npe[i], temp_sir_post_reference, lengthscale=median_heuristic(temp_sir_post_reference))\n",
    "    mmd_canpe[i] = MMD_unweighted(posterior_samples_canpe[i], temp_sir_post_reference, lengthscale=median_heuristic(temp_sir_post_reference))\n",
    "    cost_npe[i] = torch.tensor(checkpoint[\"cost_npe\"])\n",
    "    cost_canpe[i] = torch.tensor(checkpoint[\"cost_canpe\"])\n",
    "    \n",
    "    cost_saved[i] = 1 - cost_canpe[i] / cost_npe[i]\n",
    "    \n",
    "mmd_npe = mmd_npe.detach().numpy() \n",
    "mmd_npe_mean = np.mean(mmd_npe)\n",
    "mmd_npe_std = np.std(mmd_npe)\n",
    "\n",
    "mmd_canpe = mmd_canpe.detach().numpy() \n",
    "mmd_canpe_mean = np.mean(mmd_canpe)\n",
    "mmd_canpe_std = np.std(mmd_canpe)\n",
    "\n",
    "cost_npe = cost_npe.detach().numpy() \n",
    "cost_npe_mean = np.mean(cost_npe)\n",
    "cost_npe_std = np.std(cost_npe)\n",
    "\n",
    "cost_canpe = cost_canpe.detach().numpy() \n",
    "cost_canpe_mean = np.mean(cost_canpe)\n",
    "cost_canpe_std = np.std(cost_canpe)\n",
    "\n",
    "cost_saved = cost_saved.detach().numpy()\n",
    "cost_saved_mean = np.mean(cost_saved)\n",
    "cost_saved_std = np.std(cost_saved)\n",
    "\n",
    "print(f\"NPE MMD mean {mmd_npe_mean:.2f} (std {mmd_npe_std:.2f})\")\n",
    "print(f\"CA-NPE MMD mean {mmd_canpe_mean:.2f} (std {mmd_canpe_std:.2f})\")\n",
    "\n",
    "print(f\"NPE cost mean {cost_npe_mean:.2f} (std {cost_npe_std:.2f})\")\n",
    "print(f\"CA-NPE cost mean {cost_canpe_mean:.2f} (std {cost_canpe_std:.2f})\")\n",
    "\n",
    "print(f\"Cost saved: {cost_saved_mean}(std {cost_saved_std})\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "8c7fdb2c",
   "metadata": {},
   "source": [
    "k = 1.0\n",
    "n_run = 50\n",
    "mmd_npe = torch.zeros([n_run])\n",
    "posterior_samples_npe = torch.zeros([n_run, 1000, 2])\n",
    "cost_npe = torch.zeros([n_run])\n",
    "mmd_canpe = torch.zeros([n_run])\n",
    "posterior_samples_canpe = torch.zeros([n_run, 1000, 2])\n",
    "cost_canpe = torch.zeros([n_run])\n",
    "\n",
    "cost_saved = torch.zeros([n_run])\n",
    "\n",
    "\n",
    "for i in range(n_run):\n",
    "    checkpoint_path = f\"sims/temp_sir/{k}/{i+1}/ckpt.tar\"\n",
    "    checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "\n",
    "    posterior_npe = checkpoint[\"posterior_npe\"]\n",
    "    posterior_canpe = checkpoint[\"posterior_canpe\"]\n",
    "    \n",
    "\n",
    "#     posterior_samples_npe[i] = checkpoint[\"posterior_samples_npe\"]\n",
    "#     posterior_samples_canpe[i] = checkpoint[\"posterior_samples_canpe\"]\n",
    "    \n",
    "    posterior_samples_npe[i] = posterior_npe.sample((1000,), x=temp_sir_obs_x, show_progress_bars=False)\n",
    "    posterior_samples_canpe[i] = posterior_canpe.sample((1000,), x=temp_sir_obs_x, show_progress_bars=False)\n",
    "    \n",
    "    mmd_npe[i] = MMD_unweighted(posterior_samples_npe[i], temp_sir_post_reference, lengthscale=median_heuristic(temp_sir_post_reference))\n",
    "    mmd_canpe[i] = MMD_unweighted(posterior_samples_canpe[i], temp_sir_post_reference, lengthscale=median_heuristic(temp_sir_post_reference))\n",
    "    cost_npe[i] = torch.tensor(checkpoint[\"cost_npe\"])\n",
    "    cost_canpe[i] = torch.tensor(checkpoint[\"cost_canpe\"])\n",
    "    \n",
    "    cost_saved[i] = 1 - cost_canpe[i] / cost_npe[i]\n",
    "    \n",
    "mmd_npe = mmd_npe.detach().numpy() \n",
    "mmd_npe_mean = np.mean(mmd_npe)\n",
    "mmd_npe_std = np.std(mmd_npe)\n",
    "\n",
    "mmd_canpe = mmd_canpe.detach().numpy() \n",
    "mmd_canpe_mean = np.mean(mmd_canpe)\n",
    "mmd_canpe_std = np.std(mmd_canpe)\n",
    "\n",
    "cost_npe = cost_npe.detach().numpy() \n",
    "cost_npe_mean = np.mean(cost_npe)\n",
    "cost_npe_std = np.std(cost_npe)\n",
    "\n",
    "cost_canpe = cost_canpe.detach().numpy() \n",
    "cost_canpe_mean = np.mean(cost_canpe)\n",
    "cost_canpe_std = np.std(cost_canpe)\n",
    "\n",
    "cost_saved = cost_saved.detach().numpy()\n",
    "cost_saved_mean = np.mean(cost_saved)\n",
    "cost_saved_std = np.std(cost_saved)\n",
    "\n",
    "print(f\"NPE MMD mean {mmd_npe_mean:.2f} (std {mmd_npe_std:.2f})\")\n",
    "print(f\"CA-NPE MMD mean {mmd_canpe_mean:.2f} (std {mmd_canpe_std:.2f})\")\n",
    "\n",
    "print(f\"NPE cost mean {cost_npe_mean:.2f} (std {cost_npe_std:.2f})\")\n",
    "print(f\"CA-NPE cost mean {cost_canpe_mean:.2f} (std {cost_canpe_std:.2f})\")\n",
    "\n",
    "print(f\"Cost saved: {cost_saved_mean}(std {cost_saved_std})\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "5e0a1ca0",
   "metadata": {},
   "source": [
    "k = 2.0\n",
    "n_run = 100\n",
    "mmd_npe = torch.zeros([n_run])\n",
    "posterior_samples_npe = torch.zeros([n_run, 1000, 2])\n",
    "cost_npe = torch.zeros([n_run])\n",
    "mmd_canpe = torch.zeros([n_run])\n",
    "posterior_samples_canpe = torch.zeros([n_run, 1000, 2])\n",
    "cost_canpe = torch.zeros([n_run])\n",
    "\n",
    "cost_saved = torch.zeros([n_run])\n",
    "\n",
    "\n",
    "for i in range(n_run):\n",
    "    checkpoint_path = f\"sims/temp_sir/{k}/{i+1}/ckpt.tar\"\n",
    "    checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "\n",
    "    posterior_npe = checkpoint[\"posterior_npe\"]\n",
    "    posterior_canpe = checkpoint[\"posterior_canpe\"]\n",
    "    \n",
    "\n",
    "#     posterior_samples_npe[i] = checkpoint[\"posterior_samples_npe\"]\n",
    "#     posterior_samples_canpe[i] = checkpoint[\"posterior_samples_canpe\"]\n",
    "    \n",
    "    posterior_samples_npe[i] = posterior_npe.sample((1000,), x=temp_sir_obs_x, show_progress_bars=False)\n",
    "    posterior_samples_canpe[i] = posterior_canpe.sample((1000,), x=temp_sir_obs_x, show_progress_bars=False)\n",
    "    \n",
    "    mmd_npe[i] = MMD_unweighted(posterior_samples_npe[i], temp_sir_post_reference, lengthscale=median_heuristic(temp_sir_post_reference))\n",
    "    mmd_canpe[i] = MMD_unweighted(posterior_samples_canpe[i], temp_sir_post_reference, lengthscale=median_heuristic(temp_sir_post_reference))\n",
    "    cost_npe[i] = torch.tensor(checkpoint[\"cost_npe\"])\n",
    "    cost_canpe[i] = torch.tensor(checkpoint[\"cost_canpe\"])\n",
    "    \n",
    "    cost_saved[i] = 1 - cost_canpe[i] / cost_npe[i]\n",
    "    \n",
    "mmd_npe = mmd_npe.detach().numpy() \n",
    "mmd_npe_mean = np.mean(mmd_npe)\n",
    "mmd_npe_std = np.std(mmd_npe)\n",
    "\n",
    "mmd_canpe = mmd_canpe.detach().numpy() \n",
    "mmd_canpe_mean = np.mean(mmd_canpe)\n",
    "mmd_canpe_std = np.std(mmd_canpe)\n",
    "\n",
    "cost_npe = cost_npe.detach().numpy() \n",
    "cost_npe_mean = np.mean(cost_npe)\n",
    "cost_npe_std = np.std(cost_npe)\n",
    "\n",
    "cost_canpe = cost_canpe.detach().numpy() \n",
    "cost_canpe_mean = np.mean(cost_canpe)\n",
    "cost_canpe_std = np.std(cost_canpe)\n",
    "\n",
    "cost_saved = cost_saved.detach().numpy()\n",
    "cost_saved_mean = np.mean(cost_saved)\n",
    "cost_saved_std = np.std(cost_saved)\n",
    "\n",
    "print(f\"NPE MMD mean {mmd_npe_mean:.2f} (std {mmd_npe_std:.2f})\")\n",
    "print(f\"CA-NPE MMD mean {mmd_canpe_mean:.2f} (std {mmd_canpe_std:.2f})\")\n",
    "\n",
    "print(f\"NPE cost mean {cost_npe_mean:.2f} (std {cost_npe_std:.2f})\")\n",
    "print(f\"CA-NPE cost mean {cost_canpe_mean:.2f} (std {cost_canpe_std:.2f})\")\n",
    "\n",
    "print(f\"Cost saved: {cost_saved_mean}(std {cost_saved_std})\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "87f82ebc",
   "metadata": {},
   "source": [
    "seed = 4\n",
    "plt.figure(figsize=[13,5])\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.xlim(0, 1)\n",
    "sns.kdeplot(temp_sir_post_reference[:,0], color = \"C1\", linewidth = 2, linestyle = \"solid\", label = \"NPE (reference)\")\n",
    "sns.kdeplot(posterior_samples_canpe[seed,:,0], color = \"C2\", linewidth = 2, linestyle = \"solid\", label = \"CA-NPE\")\n",
    "sns.kdeplot(posterior_samples_npe[seed,:,0], color = \"C4\", linewidth = 2, linestyle = \"solid\", label = \"NPE\")\n",
    "plt.axvline(x=temp_sir_obs_theta.detach().numpy()[0], color='r', linestyle='--', linewidth=2, label='$\\\\theta_{true}$')\n",
    "\n",
    "plt.xlabel(\"$\\\\beta$\", fontsize = 20)\n",
    "plt.ylabel(\"Density\", fontsize=20)\n",
    "# plt.title(f\"MMD:{mmd[seed]:.2f}\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.xlim(0, 1)\n",
    "sns.kdeplot(temp_sir_post_reference[:,1], color = \"C1\", linewidth = 2, linestyle = \"solid\", label = \"NPE (reference)\")\n",
    "sns.kdeplot(posterior_samples_canpe[seed,:,0], color = \"C2\", linewidth = 2, linestyle = \"solid\", label = \"CA-NPE\")\n",
    "sns.kdeplot(posterior_samples_npe[seed,:,0], color = \"C4\", linewidth = 2, linestyle = \"solid\", label = \"NPE\")\n",
    "plt.axvline(x=temp_sir_obs_theta.detach().numpy()[1], color='r', linestyle='--', linewidth=2, label='$\\\\theta_{true}$')\n",
    "plt.legend(fontsize=18, loc=1)\n",
    "plt.xlabel(\"$\\\\gamma$\", fontsize = 20)\n",
    "plt.ylabel(\"Density\", fontsize=20)\n",
    "\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "95f05e0e",
   "metadata": {},
   "source": [
    "temp_sir_obs_x.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "97ec5b46",
   "metadata": {},
   "source": [
    "temp_sir_post_npe_large.log_prob(theta=temp_sir_post_reference[1:3].reshape(2,2), x=temp_sir_obs_x.reshape(1, -1))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "13ce69eb",
   "metadata": {},
   "source": [
    "# Figure 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "94ddcdcb",
   "metadata": {},
   "source": [
    "N = 20\n",
    "n_rep = 50\n",
    "\n",
    "beta_range = np.linspace(0, 1, N)\n",
    "gamma_range = np.linspace(0, 1, N)\n",
    "\n",
    "beta_grid, gamma_grid = np.meshgrid(beta_range, gamma_range)\n",
    "theta_grid = np.hstack((beta_grid.reshape(-1, 1), gamma_grid.reshape(-1, 1)))\n",
    "\n",
    "cost_real = np.zeros([N, N])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "e9f9db37",
   "metadata": {},
   "source": [
    "for i in range(N):\n",
    "    for j in range(N):\n",
    "        st = time.time()\n",
    "        for _ in range(n_rep):\n",
    "            result = temp_sir(torch.tensor([beta_range[i], gamma_range[j]]))\n",
    "        et = time.time()\n",
    "        cost_real[i, j] = (et - st) / n_rep\n",
    "    print(i)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1474ad68",
   "metadata": {},
   "source": [
    "cost_real = np.load(\"data/temporal_sir_cost_fig1.npy\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "54e1e526",
   "metadata": {},
   "source": [
    "beta_range = np.linspace(0, 1, N)\n",
    "gamma_range = np.linspace(0, 1, N)\n",
    "sns.set(style=\"white\")\n",
    "\n",
    "plt.figure(figsize=(7.5, 6))\n",
    "sns.heatmap(cost_real.T, xticklabels=np.round(beta_range, 1), yticklabels=np.round(gamma_range, 1), annot=False, fmt=\".2f\", cmap='Reds').invert_yaxis()\n",
    "# plt.title('Cost Heatmap by $\\\\beta$ and $\\\\gamma$', size=25)\n",
    "plt.xlabel('$\\\\theta_1$', size=20)\n",
    "plt.ylabel('$\\\\theta_2$', size=20)\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3d1a74",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
